# Kōan Configuration
#
# IMPORTANT: Values starting with "CHANGE:" must be updated before running.
# Kōan will work with sensible defaults for most other settings.

# CLI provider — which AI agent backend to use
# Options: "claude" (default), "copilot" (GitHub Copilot CLI), "local" (local LLM)
# Override via KOAN_CLI_PROVIDER env var
cli_provider: "claude"

# Local LLM configuration (only used when cli_provider: "local")
# Connects to any OpenAI-compatible API server:
#   - Ollama:       http://localhost:11434/v1  (default, `ollama serve`)
#   - llama.cpp:    http://localhost:8080/v1   (`llama-server -m model.gguf`)
#   - LM Studio:    http://localhost:1234/v1   (start local server in app)
#   - vLLM:         http://localhost:8000/v1   (`vllm serve model_name`)
#
# Env var overrides: KOAN_LOCAL_LLM_BASE_URL, KOAN_LOCAL_LLM_MODEL, KOAN_LOCAL_LLM_API_KEY
#
# Example models (via Ollama):
#   ollama pull glm4                  # GLM 4 (9B, good for code)
#   ollama pull kimi-k2               # Kimi K2 (when available)
#   ollama pull nemotron-mini          # Nvidia Nemotron Mini
#   ollama pull qwen2.5-coder:7b     # Qwen 2.5 Coder
#   ollama pull codellama:13b         # Code Llama
#
# local_llm:
#   base_url: "http://localhost:11434/v1"
#   model: "glm4"           # Model name as known by the server
#   api_key: ""              # Usually empty for local servers

# Paths — these are mostly set via environment variables now.
# You can override here if needed, but KOAN_PROJECT_PATH / KOAN_PROJECTS
# in .env is the preferred method.
# project_path: "/path/to/your/project"
# pilot_repo: "/path/to/koan"

# Budget & Scheduling
max_runs_per_day: 20
interval_seconds: 300  # 5 minutes between runs

# Fast reply mode — use lightweight model (Haiku) for command handlers
# When true, /usage, /sparring, and similar commands use Haiku instead of default model
# Faster response, lower cost, but simpler answers
fast_reply: false

# Contemplative mode trigger chance (0-100%)
# When no mission is pending, this is the probability of running a reflective
# session instead of autonomous work. Allows regular moments of introspection
# without waiting for budget exhaustion.
# 0 = never contemplative, 10 = ~1 in 10 runs, 20 = ~1 in 5 runs
contemplative_chance: 10

# Telegram
# NOTE: Prefer setting these in .env (KOAN_TELEGRAM_TOKEN, KOAN_TELEGRAM_CHAT_ID)
# These config values are only used if the env vars are not set.
telegram:
  bot_token: ""   # Set via KOAN_TELEGRAM_TOKEN in .env (recommended)
  chat_id: ""     # Set via KOAN_TELEGRAM_CHAT_ID in .env (recommended)

# Usage thresholds
budget:
  warn_at_percent: 70   # Send warning via Telegram
  stop_at_percent: 85   # Stop running

# Claude tools configuration
# These tools will be available when Claude is invoked for chat responses
tools:
  allowed: ["Read", "Glob", "Grep", "Edit", "Write", "Bash"]
  description: |
    Available capabilities:
    - File operations: Read, Edit, Write files in the project
    - Search: Glob (find files), Grep (search content)
    - Shell: Bash (run git, gh, make, and other commands)

# Claude model configuration
# Controls which models are used for different types of Claude calls
# Empty string = use default model (subscription default or ANTHROPIC_MODEL)
models:
  mission: ""              # Main mission execution (empty = default)
  chat: ""                 # Telegram/dashboard chat responses
  lightweight: "haiku"     # Low-cost calls: format_outbox, pick_mission, contemplative
  fallback: "sonnet"       # Fallback when primary model is overloaded (print mode only)
  review_mode: ""          # Override model for REVIEW mode (cheaper audits)

# Git auto-merge configuration
# Automatically merges koan/* branches based on rules
git_auto_merge:
  enabled: false                    # Global on/off switch
  base_branch: "main"               # Default target branch for merges
  strategy: "squash"                # merge | squash | rebase
  rules:
    - pattern: "koan/*"             # Branch name pattern (glob-style)
      auto_merge: true              # Enable auto-merge for matching branches
      delete_after_merge: true      # Clean up branch after successful merge

# Usage estimation (auto-calibration from Claude JSON output)
# Tune these limits based on your Claude plan by comparing
# estimated % with actual /usage output in Claude CLI
usage:
  session_token_limit: 500000   # Tokens per 5h session window
  weekly_token_limit: 5000000   # Tokens per 7-day window

# Per-project overrides
# Override git_auto_merge settings for specific projects
# Example: if you have a project named "myapp" configured via KOAN_PROJECTS
# projects:
#   myapp:
#     git_auto_merge:
#       enabled: true
#       base_branch: "main"
#       strategy: "squash"
